\documentclass{ExerciseSheet}

%Set Number of the Exercise sheet and the submission deadline.
\setExerciseSheetNumber{8}
\setSubmissionDate{xx.xx.2024}

%boolean variable to determine whether the solutions should be included
\newif\ifsolutions
\solutionstrue
%\solutionsfalse

%We have a figure in this sheet
\usepackage{graphicx}

\begin{document}


%Start with exercises
%-----------------------------------------------------------------------%


\subsection*{Notation}
\vskip 0.5cm 
%-----------------------------------------------------------------------%
\begin{problem}

For a set $K\subset \R^n$ and $p\in \N$, $x_i \in K$, $1\leq i\leq p$, and scalars $\lambda_i \geq 0$, $1\leq i\leq p$, satisfying $ \displaystyle\sum_{i=1}^{p}{\lambda_i}=1$ one denotes by $ \displaystyle\sum_{i=1}^{p}{\lambda_i x_i}$ the \emph{convex combinations of elements from $K$}. 

\begin{enumerate}
 \item Prove that a set $K \subset \R^n$ is convex if and only if every convex combination of elements from $K$ is contained in $K$.

 \item Let $f$ be convex and $D = \left\{\displaystyle\sum_{i=0}^{n}\lambda_ix_i ~|~ \lambda_i\geq0, \sum_{i=0}^{n}\lambda_i=1\right\}$
 % \begin{enumerate}
 
       Prove that 
         \begin{align*}
             \forall x\in D ~~ f(x) \leq \displaystyle\max_{i\in\{0,\dots,n\}}f(x_i)
         \end{align*}
         %\item [(ii)] Set $\displaystyle\max_{i\in\{0,\dots,n\}}f(x_i):= C$ and show that $f(x)\le C$ for all $x\in\Delta$ 
  %\end{enumerate}
 \end{enumerate}

\end{problem}

\ifsolutions
\vskip 0.3cm

\begin{solution}
\begin{enumerate}
    \item ($\Leftarrow$) Let assume every convex combination of elements from $K$ is contained in $K$ and prove $K$ is convex.\\
    Let $x,y\in K$ and $\lambda\in [0, 1],$ given that every convex combination of element of $K$ belong to $K$ then particularly $(1-\lambda)x+\lambda y\in K.$\\
    ($\Rightarrow$) Now let us assume $K\subset \R^n$ is convex and show that every convex combination of elements from $K$ is contained in $K$ i.e. $\displaystyle \sum_{i=1}^{p}\lambda_ix_i\in K.$ We will show this by induction.\\
    Induction start:  $p=1,$ is trivial and for $p=2,$~ $\lambda_1x_1+\lambda_2x_2\in K$ by definition as $K$ is convex.\\
    Let assume $\displaystyle \sum_{i=1}^{p}\lambda_ix_i\in K$ with $x_i\in K$ and $\displaystyle \sum_{i=1}^{p}\lambda_i=1$ then prove $\displaystyle \sum_{i=1}^{p+1}\lambda_ix_i\in K$ with $x_i\in K$ and $\displaystyle \sum_{i=1}^{p+1}\lambda_i=1.$
    We have
      \begin{align}
          \sum_{i=1}^{p+1}\lambda_ix_i&= \sum_{i=1}^{p}\lambda_ix_i+\lambda_{p+1}x_{p+1}\nonumber\\
                           &=(1-\lambda_{p+1})\sum_{i=1}^{p}\frac{\lambda_i}{1-\lambda_{p+1}}x_i+\lambda_{p+1}x_i \label{ induction step}
      \end{align}
    On the other hand, $0\leq \lambda_{p+1}\leq 1,~\frac{\lambda_i}{1-\lambda_{p+1}}\geq0$ and in addition, $\displaystyle \sum_{i=1}^{p+1}\lambda_i=1$ that is $\displaystyle \sum_{i=1}^{p}\lambda_i+ \lambda_{p+1}=1$ we have
    \begin{align*}
        \sum_{i=1}^{p}\lambda_i=1-\lambda_{p+1}
    \end{align*}
   therefore,
   \begin{align*}
        \sum_{i=1}^{p}\frac{\lambda_i}{1-\lambda_{p+1}}=\frac{1-\lambda_{p+1}}{1-\lambda_{p+1}}=1
    \end{align*}
 which means $\displaystyle \sum_{i=1}^{p}\frac{\lambda_i}{1-\lambda_{p+1}}x_i\in K$ by induction hypothesis.Therefore, by using the convexity of $K$ we get 
  \begin{align*}
      (1-\lambda_{p+1})\sum_{i=1}^{p}\frac{\lambda_i}{1-\lambda_{p+1}}x_i+\lambda_{p+1}x_i\in K.
  \end{align*}
 It follows from $\eqref{ induction step}$ that $\displaystyle \sum_{i=1}^{p+1}\lambda_ix_i\in K$
 




    \item Let $x\in D$ and prove 
       \begin{align*}
           f(x)\leq \max_{i\in \{0,\dots,n\}}f(x_i)
       \end{align*}
 $x\in D,$ means $\displaystyle x=\sum_{i=0}^{n}\lambda_ix_i$ with $\displaystyle \lambda_i\geq 0,~\sum_{i=0}^{n}\lambda_i=1.$ Therefore,
   \begin{align*}
       f(x)&=f\left(\sum_{i=0}^{n}\lambda_ix_i\right)  \\
           &\leq \sum_{i=0}^{n}\lambda_if(x_i)  \text{ since $f$ in convex}\\
           &\leq  \left(\max_{i\in \{0,\dots,n\}}f(x_i)\right)\sum_{i=0}^{n}\lambda_i \\
           &=\max_{i\in \{0,\dots,n\}}f(x_i)  \text{ since $\sum_{i=0}^{n}\lambda_i=1$}
   \end{align*}





       
\end{enumerate}
\end{solution}

\fi

%-----------------------------------------------------------------------%
\vskip 0.5cm
\begin{problem}

  
 Let $f:\R^n\rightarrow\R$ be strictly convex. Prove that
 \begin{enumerate}
  \item The lower level set 
  \begin{align*}
   U(f,a):=\{x \in\R^n\,:\,f(x)\leq a\}
  \end{align*}
with $a\in\R$ is convex.
\item Let $x^*\in\R^n$ be a minimizer of $f$. Prove that $U(f,f(x^*))=\{x^*\}$. 
\item Is $f$ necessarily convex if all lower level sets of $f$ are convex? Justify your answer.
 \end{enumerate}
 


\end{problem}

\ifsolutions
\vskip 0.3cm

\begin{solution}
\begin{enumerate}
    \item Let $x,y\in  U(f,a)$ and $\lambda\in [0,~1]$ let us show $(1-\lambda)x+\lambda y\in  U(f,a).$\\
    For $\lambda=0,1$ we have  $(1-\lambda)x+\lambda y\in  U(f,a).$ 
  Now let $\lambda\in (0,1)$ the strictly convexity of $f$ yields
  \begin{align*}
      f( (1-\lambda)x+\lambda y) &< (1-\lambda)f(x)                                 +\lambda f(y)\\
                                &<(1-\lambda)a+\lambda a\\
                                &=a
  \end{align*}
where we get the second inequality by using the fact that $x,~y\in U(f,a)$ means $f(x)\leq a$ and $f(y)\leq a.$ It follows from the last inequality that $(1-\lambda)x+\lambda y\in U(f,a).$
 \item Let $x^*\in\R^n$ be a minimizer of $f$ and let us prove $U\left(f,f(x^*)\right)=\{x^*\}.$\\
 Let $y\in U\left(f,f(x^*)\right)$ and assume by contradiction that $y\neq x^*.$ For $\lambda\in [0,~1]$ applying the strictly convexity of $f$ to $y,~x^*$ yields  
   \begin{align*}
       f( (1-\lambda)x^*+\lambda y) &< (1-\lambda)f(x*) +\lambda f(y)\\
       &< (1-\lambda)f(x^*) \lambda f(x^*) \text{ since $y\in U\left(f,f(x^*)\right)$}\\
       &=f(x^*)
   \end{align*}
 the last inequality above contradict the fact that $x^*$ is a minimizer, therefore, $y=x^*.$ 
 \item The Statement is not true in general. For instance,
 Consider \begin{align*}
         f: \R_+\to \R\\
         x \mapsto \sqrt{x}
 \end{align*}
  $f$ is concave and its lower level set $U(f,a)$ given by
    \begin{align*}
        U(f,a)=\begin{cases}
            (-\infty, a^2] &if ~a\geq 0\\
            \emptyset    &~~otherwise
        \end{cases}
    \end{align*}
    is convex.
\end{enumerate}
\end{solution}

\fi

%-----------------------------------------------------------------------%
\vskip 0.5cm

\begin{exo}[Gradient characterization of convex functions]\label{thm:gradient_ineq}
	Let $f\in \C(C)$, where $C$ is convex. 
 
 Prove that $f$ is convex over $C$ if and only if
	\begin{equation}\label{eq:grad_ineq}
		f(x) +\nabla f(x)^T(y-x)\leq f(y) \quad \forall x, y\in C.
	\end{equation}
\end{exo}

\ifsolutions
\vskip 0.3cm
\begin{solution}

\begin{itemize}
    \item [($\Rightarrow$)] Let us assume $f$ is convex and show that
    \begin{equation*}%\label{eq:grad_ineq}
		f(x) +\nabla f(x)^T(y-x)\leq f(y) \quad \forall x, y\in C.
	\end{equation*}
 Let $x, y\in C$ and $\lambda \in (0, 1].$ We will focus on the case $x\neq y$ as $\eqref{eq:grad_ineq}$ is trivial for $x=y.$
 The convexity of $f$ gives
 \begin{align*}
     f\left(\lambda y + (1-\lambda)x\right) \leq \lambda f(y) + (1-\lambda)f(x)
 \end{align*}
that is 
  \begin{align*}
     f\left(x+\lambda (y-x)\right) \leq \lambda f(y) + f(x)-\lambda f(x)
 \end{align*}
sending $f(x)$ on the left side and diving by $\lambda$ yields
   \begin{align*}
     \frac{f\left(x+\lambda (y-x) \right) - f(x)}{\lambda}\leq f(y)- f(x)
 \end{align*}
letting $\lambda$ tend to $0^+$ yields
        \begin{align*}
     f'(x;y-x)\leq f(y)- f(x) \text{ where $f'(x;y-x)$ is the directional }
 \end{align*}
 Given that, $f$ is continuously differentiable we have $f'(x;y-x)=\nabla f(x)^T(y-x)$ and substituting this into the above inequality gives  
    \begin{align*}
     \nabla f(x)^T(y-x)\leq f(y)- f(x) 
 \end{align*}
which prove $\ref{eq:grad_ineq}.$
\item [($\Leftarrow$)] Now let us assume $\eqref{eq:grad_ineq}$ holds and prove that $f$ is convex over $C.$\\
Let $x,~y\in C,$ and $\lambda\in (0,~1).$ Set $x'=(1-\lambda)x+\lambda y$ then $x'\in C$ since $C$ is convex, and $y=\frac{x'-(1-\lambda)x}{\lambda}$ it follows
   \begin{align}
       y-x' &= \frac{x'-(1-\lambda)x-\lambda x'}{\lambda}\nonumber\\
            &=-\frac{(1-\lambda)}{\lambda}(x-x')   \label{y-x'}
   \end{align}
 Applying $\eqref{eq:grad_ineq}$ on the pairs $x',~y$ and $x',~x$ gives           
    \begin{align}
        f(x') +\nabla f(x')^T(y-x')\leq f(y) \label{intermediate step 1}\\
        f(x') +\nabla f(x')^T(x-x')\leq f(x)  \label{intermediate step 2}
    \end{align}

    substituting $\eqref{y-x'}$ into $\eqref{intermediate step 2}$ yields
     \begin{align*}
         f(x') -\frac{\lambda}{(1-\lambda)}\nabla f(x')^T(y-x')\leq f(x)
     \end{align*}
    multiplying $\eqref{intermediate step 1}$ by $\frac{\lambda}{(1-\lambda)}$ and adding it the above gives
        \begin{align*}
           f(x')+ \frac{\lambda}{(1-\lambda)}f(x') \leq f(x) + \frac{\lambda}{(1-\lambda)}f(y)
        \end{align*}
    that is
     \begin{align*}
            \frac{1}{(1-\lambda)}f(x') \leq f(x) + \frac{\lambda}{(1-\lambda)}f(y)
        \end{align*}
    which implies
        \begin{align*}
            f(x') \leq (1-\lambda)f(x) + \lambda f(y)
        \end{align*}
    recalling $x'=(1-\lambda)x+\lambda y$ we have
     \begin{align*}
            f((1-\lambda)x+\lambda y) \leq (1-\lambda)f(x) + \lambda f(y)
        \end{align*}
\end{itemize}

\end{solution}

\fi

%-----------------------------------------------------------------------%
\vskip 0.5cm
\begin{exo}

 Let $A\subset \R^d,$ $$\text{conv}(A)=\left\{\displaystyle\sum_{i=1}^p\lambda_i x_i\,:\,\displaystyle\sum_{i=1}^p\lambda_i=1,~\lambda_i\geq 0,~ x_i \in A\text{ for all } i=1,\ldots,p\right\}$$

\item Use Jensen's inequality (Theorem 1.1 of the lecture note Chapter 3) to show the following 2 propositions
\begin{itemize}
    \item Let $f:\text{conv}(A)\rightarrow \R$ be convex. Show 
    \begin{align*}
     \sup_{x \in \text{conv}(A)} f(x)=\sup_{x\in A} f(x). 
    \end{align*}

    \item Show that for all $x\in \R^n$ such that $x_i >0$, $1\leq i\leq n$ the following inequality between the arithmetic and geometric mean holds:
	\begin{align*}
	\left( \prod_{i=1}^n x_i \right)^{\frac{1}{n}} \leq \frac{1}{n} \sum_{i=1}^n x_i.
	\end{align*}
 \end{itemize}


\end{exo}

\ifsolutions
\vskip 0.3cm
\begin{solution}
\begin{itemize}
    \item Let us prove 
            \begin{align*}
                 \sup_{x \in \text{conv}(A)} f(x)=\sup_{x\in A} f(x). 
            \end{align*}
        $\text{conv}(A)$ is the smallest convex set containing A, hence, $A\subset \text{conv}(A).$ Therefore,
            $$\sup_{x \in \text{conv}(A)} f(x)\geq\sup_{x\in A} f(x).$$
        Let us now show 
            $$\sup_{x \in \text{conv}(A)} f(x)\leq\sup_{x\in A} f(x).$$
        We have
        \begin{align*}
            \sup_{x \in \text{conv}(A)}f(x) &= \sup_{x_i \in A,~\sum_{i=1}^{p}\lambda_i=1,~0\leq \lambda_i\leq 1}f\left(\sum_{i=1}^{p}\lambda_ix_i\right) 
        \end{align*}
        Since $f$ is convex applying Jensen's inequality (Theorem 1.1 of the lecture note Chapter 3) on the right hand side gives
        \begin{align*}
            \sup_{x \in \text{conv}(A)}f(x) &\leq \sup_{x_i \in A,~\sum_{i=1}^{p}\lambda_i=1,~0\leq \lambda_i\leq 1}\left(\sum_{i=1}^{p} \lambda_if(x_i)\right) \\
                                            &\leq \sup_{x\in A}f(x)\left( \sup_{\sum_{i=1}^{p}\lambda_i=1,~0\leq \lambda_i\leq 1}\sum_{i=1}^{p} \lambda_i\right) \\
                                            &= \sup_{x\in A}f(x) \text{ since $\sum_{i=1}^{p} \lambda_i=1$}
        \end{align*}
        
    \item For $i,~1\leq i\leq n$ set $y_i=\ln{x_i}.$ Then
        \begin{align*}
            \left(\prod_{i=1}^{n}x_i\right)^{\frac{1}{n}}&= \left(\prod_{i=1}^{n}e^{y_i}\right)^{\frac{1}{n}} \\
                                                          &=  \left(e^{\sum_{i=1}^{n}y_i}\right)^{\frac{1}{n}} \\
                                                           &= e^{\frac{1}{n}\sum_{i=1}^{n}y_i}
        \end{align*}
    Given that, $e$ (exponential) is convex, applying Jensen's inequality yields
    
        \begin{align*}
            \left(\prod_{i=1}^{n}x_i\right)^{\frac{1}{n}}&\leq \sum_{i=1}^{n}e^{y_i}\\
                                                         &= \sum_{i=1}^{n}x_i
        \end{align*}
    

\end{itemize}     
\end{solution}
\fi

%-----------------------------------------------------------------------%
\vskip 0.5cm
\begin{exo}
Prove the following statements 
\begin{enumerate} 
 \item The intersection $\displaystyle\bigcap_{i\in I} K_i$ of arbitrarily many convex sets $K_i\,,\ i\in I,$ is convex. %%% Lemma 6.6 of [1] %%%
  \item For two convex sets $K_1\,,\ K_2\subset\R^n$ we have that the difference
  $$
K_1-K_2\ =\ \{\ v_1-v_2 \ : \ v_1\in K_1\,,\ v_2\in K_2 \ \}
$$
is convex.
\item For a convex set $K\subset\R^n$ the set
$K_0=\{\,\mu\,v \ : \ v\in K,\ \mu>0\,\}$ is convex as well.
\end{enumerate}
	
\end{exo}

\ifsolutions
\vskip 0.3cm
\begin{solution}
    \begin{enumerate}
        \item Let $x,~y\in \bigcap_{i\in I} K_i$ and $\lambda_i\in [0,~1].$ Then for all $i\in I,$ we have $x,~y\in K_i.$
            Given that all $K_i,~i\in I$ are convex, \\
            \begin{align*}
                (1-\lambda)x+\lambda y\in K_i~~ i\in I,~~  \lambda\in [0, 1]
            \end{align*}
            hence,
            \begin{align*}
                (1-\lambda)x+\lambda y\in \bigcap_{i\in I} K_i.
            \end{align*}
        \item Let us show that 
                \begin{align*}
                    K_1 - K_2 =\{ v_1 - v_2 \ : \ v_1\in K_1\,,\ v_2\in K_2 \ \} 
                \end{align*}
                is convex. Let $x,~y\in K_1 - K_2$ then there exist $u_1,~v_1\in K_1$ and $u_2,~v_2\in K_2$ such that\\ $x=u_1-u_2$ and $y=v_1-v_2.$ It follows
                \begin{align*}
                    (1-\lambda)x+\lambda y  &= (1-\lambda)u_1-(1-\lambda)u_2-\lambda v_1+\lambda v_2 \\
                                            &= (1-\lambda)u_1 - \lambda v_1 - \left( (1-\lambda)u_2 - \lambda v_2 \right)
                \end{align*}
            Note that by the convexity of $K_1$ and $K_2,$ we have $(1-\lambda)u_1 - \lambda v_1\in K_1$ and $(1-\lambda)u_2 - \lambda v_2 \in K_2.$ Consequently,
            \begin{align*}
                (1-\lambda)x+\lambda y \in  K_1 - K_2.
            \end{align*}
        \item Let us show $K_0=\{\,\mu\,v \ : \ v\in K,\ \mu>0\,\}$ is convex.\\
           Let $x,~y\in K_0.$ If $\lambda\in\{0,~1\}$ then $ (1-\lambda)x+\lambda y \in K_0.$\\
            Now let consider $\lambda\in (0,~1),~~\mu>0$ and show $ (1-\lambda)x+\lambda y \in K_0.$ Given that,  $x,~y\in K_0$ there exist $x',~y'\in K$ and $\mu_x,~\mu_y>0$ such that
             \begin{align*}
                 \begin{cases}
                     x=\mu_x x'\\
                     y=\mu_y y'
                 \end{cases}
             \end{align*}
             Given that $K$ convex, it suffices to find $k\in(0,~1)$ such that 
             \begin{align*}
                 (1-\lambda)x+\lambda y = \mu((1-k)x'+k y' )
             \end{align*}
            that is
            \begin{align*}
                 (1-\lambda)\mu_xx'+\lambda \mu_yy' = \mu((1-k)x'+k y' )
             \end{align*}
        it follows
            \begin{align*}
                 (1-\lambda)\mu_x = \mu(1-k) \text{ and } \lambda \mu_y = \mu k 
             \end{align*}
        consequently
             \begin{align*}
                 \frac{1-\lambda)\mu_x}{1-k} = \frac{\lambda\mu_y}{k}
             \end{align*}
        hence, take
        \begin{align*}
            k = \frac{1}{1+ \frac{(1-\lambda)\mu_x}{\lambda \mu_y}}
        \end{align*}
    \end{enumerate}
\end{solution}
\fi

\end{document}