\documentclass{ExerciseSheet}

%Set Number of the Exercise sheet and the submission deadline.
\setExerciseSheetNumber{12}
\setSubmissionDate{xx.xx.2024}

%boolean variable to determine whether the solutions should be included
\newif\ifsolutions
\solutionstrue
%\solutionsfalse

%We have a figure in this sheet
\usepackage{graphicx}

\begin{document}


%Start with exercises
%-----------------------------------------------------------------------%



\begin{problem}
Let $a_1, a_2, \ldots, a_p \in \mathbb{R}^n $, $ p \in \mathbb{N} $. Then $\operatorname{cone}(\{a_1, \ldots, a_p\})$ is closed and convex.
\end{problem}

\ifsolutions
\vskip 0.3cm


\begin{solution}
    Let $ C = \operatorname{cone}(\{a_1, \ldots, a_p\}) $ be the conic hull of vectors $ a_1, \ldots, a_p \in \mathbb{R}^n $.

\begin{enumerate}
    \item \textbf{Convexity:} \\
    Take any $ x, y \in C $ and $ \lambda \in [0,1] $. By definition of the conic hull, there exist non-negative coefficients $ \alpha_1, \ldots, \alpha_p $ and $ \beta_1, \ldots, \beta_p $ such that:
    \[
    x = \sum_{i=1}^p \alpha_i a_i, \quad y = \sum_{i=1}^p \beta_i a_i.
    \]
    The convex combination $ \lambda x + (1-\lambda)y $ can be written as:
    \[
    \lambda x + (1-\lambda)y = \sum_{i=1}^p (\lambda \alpha_i + (1-\lambda)\beta_i) a_i.
    \]
    Since $ \lambda \alpha_i + (1-\lambda)\beta_i \geq 0 $ for all $ i $, this shows $ \lambda x + (1-\lambda)y \in C $. Thus, $ C $ is convex.

    \item \textbf{Closedness:} We consider the set
\[
\mathbb{R}^p_{+} = \{ x \in \mathbb{R}^p : x_i \ge 0 \ \forall i \}.
\]
This set is the non-negative orthant in $\mathbb{R}^p$. It is closed and convex.

The conic hull is the linear image $A \mathbb{R}^p_{+}$.  
While the image of a closed set under a linear transformation is not always closed in general, here the set $A \mathbb{R}^p_{+}$ is a \emph{polyhedral cone}.

A \emph{polyhedral cone} is defined as a set of the form
\[
K = \{ y \in \mathbb{R}^n : B y \ge 0 \}
\]
for some matrix $B \in \mathbb{R}^{m \times n}$, i.e., an intersection of finitely many closed half-spaces.

We know that
\[
A \mathbb{R}^p_{+} = \operatorname{cone}(\{a_{1}, \dots, a_{p}\})
\]
is a polyhedral cone. Since each half-space $\{ y : b^T y \ge 0 \}$ is closed and a finite intersection of closed sets is closed, every polyhedral cone is closed. Therefore, the $\operatorname{cone}(\{a_{1}, \dots, a_{p}\})$ is closed.
    
    
\end{enumerate}

\end{solution}
\fi
%-----------------------------------------------------------------------%
\vskip 0.5cm
\begin{problem}
\begin{align}
\min\quad & f(x) \nonumber \\
\text{s.t.} \quad & x \in C
\end{align}
    Let $f \in C_L^{1,1}(C) $, with $C $ closed and convex. Let $\{x_k\}_k $ be a sequence generated by Algorithm 1 (Projected Gradient Descent (PGD), lecture note) for solving (1). Assume that $f $ is bounded below over $C $. Then we have the following:

\begin{itemize}
    \item[(a)] The sequence $\{f(x_k)\}_k $ is nonincreasing. In addition, for any $k \geq 0 $, $f(x_{k+1}) < f(x_k) $ unless $x_k $ is a stationary point.
    \item[(b)] $G_{\frac{1}{t}}(x_k) \to 0 $ as $k \to \infty $.
\end{itemize}
\end{problem}
\ifsolutions
\vskip 0.3cm

\begin{solution}
   \vskip 0.3cm  
\textbf{ Smoothness property (Descent Lemma)}: If $f$ is differentiable with Lipschitz continuous gradient (constant $L$), then for any $x, y \in \mathbb{R}^n$:

\[
f(y) \le f(x) + \langle \nabla f(x), y - x \rangle + \frac{L}{2}\|y - x\|^2
\]

\textbf{ The PGD update rule}: Let $y_k = x_k - t \nabla f(x_k), \quad t\in (0, \tfrac{L}{2})$ and $x_{k+1} = P_C(y_k)$.
\vskip 0.3cm
By the non-expansiveness of projections and convexity of $C$, we know that

\[
\langle x_{k+1} - y_k, z - x_{k+1} \rangle \ge 0 \quad \text{for all } z \in C
\]

Choose $z = x_k \in C$, then

\[
\langle x_{k+1} - y_k, x_k - x_{k+1} \rangle \ge 0
\]

Using $y_k = x_k - t \nabla f(x_k)$, we get:

\[
\langle x_{k+1} - x_k + t \nabla f(x_k), x_k - x_{k+1} \rangle \ge 0
\]

Expanding:

\[
\langle x_{k+1} - x_k, x_k - x_{k+1} \rangle + t \langle \nabla f(x_k), x_k - x_{k+1} \rangle \ge 0
\]

\[
-\|x_{k+1} - x_k\|^2 + t \langle \nabla f(x_k), x_k - x_{k+1} \rangle \ge 0
\]

\[
\Rightarrow \langle \nabla f(x_k), x_k - x_{k+1} \rangle \ge \tfrac{1}{t} \|x_{k+1} - x_k\|^2
\]

\textbf{ Apply the descent lemma}: From smoothness of $f$,

\[
f(x_{k+1}) \le f(x_k) + \langle \nabla f(x_k), x_{k+1} - x_k \rangle + \frac{L}{2}\|x_{k+1} - x_k\|^2
\]

Using the inequality above:

\[
\langle \nabla f(x_k), x_{k+1} - x_k \rangle \le -\tfrac{1}{t} \|x_{k+1} - x_k\|^2
\]

So:

\[
f(x_{k+1}) \le f(x_k) + \left(   \tfrac{L}{2} - \tfrac{1}{t}\right) \|x_{k+1} - x_k\|^2
\]

Since $t\in (0, \tfrac{L}{2})$ then $\tfrac{L}{2} - \tfrac{1}{t} \le 0$, hence:

\[
f(x_{k+1}) - f(x_k) \le 0 \]

So $\{f(x_k)\}$ is nonincreasing. Furthermore, strict inequality holds unless $x_{k+1} = x_k$, which implies $x_k = P_C(x_k - \tfrac{1}{t} \nabla f(x_k))$, i.e., a stationary point.

To show the convergence of the gradient mapping $G_{\tfrac{1}{t}}(x_k) := \tfrac{1}{t}(x_k -P_C(y_k)) $, we will use the inequality above again, let $L =1/t$:

\[
f(x_k) - f(x_{k+1}) \ge \left(   \tfrac{1}{t} - \tfrac{L}{2}  \right) \|x_{k+1} - x_k\|^2 = \frac{t^2}{2t} \|G_{\tfrac{1}{t}}(x_k)\|^2 = \frac{t}{2} \|G_{\tfrac{1}{t}}(x_k)\|^2
\]

Sum both sides over $k = 0$ to $N$ and since $f$ is bounded below on $C$

\[
\sum_{k=0}^N \|G_{\tfrac{1}{t}}(x_k)\|^2 \le \tfrac{2}{t} (f(x_0) - f(x_N))
\]

Taking the limit as $N \rightarrow \infty$, set $f^* = \inf_{x \in C} f(x)$. We have that 
\[
\sum_{k=0}^\infty \|G_{\tfrac{1}{t}}(x_k)\|^2 \le \tfrac{2}{t} (f(x_0) - f^*) < \infty
\]
So the series $\sum \|G_{\tfrac{1}{t}}(x_k)\|^2$ converges, hence:

\[
\|G_{\tfrac{1}{t}}(x_k)\| \to 0 \quad \text{as } k \to \infty
\]

\end{solution}
\fi
\begin{problem}
    Let $ f \in C_L^{1,1}(C) $, where $ C $ is convex and closed. Then for any $ x \in C $ and $ t \in \left(0, \frac{2}{L}\right) $, the following inequality holds:
\begin{equation}\label{eq:descent-pgd}
f(x) - f(P_C(x - t \nabla f(x))) \geq t \left(1 - \frac{Lt}{2}\right) \left\| \frac{1}{t}(x - P_C(x - t \nabla f(x))) \right\|^2.
\end{equation}
\end{problem}

\ifsolutions
\vskip 0.3cm
\begin{solution}
    Let $ f \in C_L^{1,1}(C) $, meaning $ f $ is differentiable with $ L $-Lipschitz continuous gradient over a closed and convex set $ C $. Then for any $ x \in C $ and step size $ t \in \left(0, \frac{2}{L}\right) $, we have:


Let $ y = x - t \nabla f(x) $ and $ x^+ := P_C(y) $ be the projected point. Define the gradient mapping:

\[
G_t(x) := \frac{1}{t}(x - x^+).
\]

We want to lower bound the decrease $ f(x) - f(x^+) $.

We will apply Descent Lemma (smoothness), since $ f $ has $ L $-Lipschitz continuous gradient, we use:

\[
f(x^+) \le f(x) + \langle \nabla f(x), x^+ - x \rangle + \frac{L}{2} \|x^+ - x\|^2.
\]

Rewriting:

\[
f(x) - f(x^+) \ge - \langle \nabla f(x), x^+ - x \rangle - \frac{L}{2} \|x^+ - x\|^2.
\]

Using the optimality of projection; from projection onto a convex set

\[
\langle x^+ - y, z - x^+ \rangle \ge 0 \quad \text{for all } z \in C.
\]

Let $ z = x \in C $, then we have 

\[
\langle x^+ - (x - t \nabla f(x)), x - x^+ \rangle \ge 0
\Rightarrow \langle x^+ - x + t \nabla f(x), x - x^+ \rangle \ge 0.
\]
We can then expand to get 

\[
\langle x^+ - x, x - x^+ \rangle + t \langle \nabla f(x), x - x^+ \rangle \ge 0,
\]

\[
- \|x^+ - x\|^2 + t \langle \nabla f(x), x - x^+ \rangle \ge 0
\Rightarrow \langle \nabla f(x), x - x^+ \rangle \ge \frac{1}{t} \|x^+ - x\|^2.
\]

Combining the above with smoothness bound, we get

\[
f(x) - f(x^+) \ge \langle \nabla f(x), x - x^+ \rangle - \frac{L}{2} \|x^+ - x\|^2 
\ge \left( \frac{1}{t} - \frac{L}{2} \right) \|x - x^+\|^2.
\]

Factoring out $ t $ to produce

\[
= t \left(1 - \frac{Lt}{2} \right) \left\| \frac{1}{t}(x - x^+) \right\|^2
= t \left(1 - \frac{Lt}{2} \right) \|G_t(x)\|^2.
\]
\end{solution}
\fi
\begin{problem}

Consider function $f$ define on $\R^2$ by
  \begin{align*}
      f(x, y) = x^4 + y^4 -2(x - y)^2.
  \end{align*}
  \begin{itemize}
      \item  Prove that there exist $\alpha\in \R_+,$ $\beta\in \R$ (and determine them) such that
      \begin{align*}
          f(x,y)\geq \alpha\|(x,y)\|^2 + \beta
      \end{align*}
    \item  Show that the problem 
        \begin{align} \label{pb}
            \inf_{(x,y)\in \R^2} f(x,y) 
        \end{align}
    possess at least one solution.
    \end{itemize}
\end{problem}

\ifsolutions
\vskip 0.3cm

    \begin{solution}

\begin{enumerate}
    \item A direct computation gives \begin{align*}
        f(x, y) = x^4 + y^4 -2x^2 -2y^2 +4xy
    \end{align*}
    Using the fact that for all $x,y\in\R~xy\geq-\frac{1}{2}(x^2+y^2)$ we get
    \begin{align*}
        f(x, y) &\geq x^4 + y^4 -4x^2 -4y^2 \\
                &= x^4 +\epsilon^4 + y^4 +\epsilon^4 -4x^2 -4y^2 -2\epsilon^4 \text{ for all $\epsilon\in\R$}
    \end{align*}
    Using the fact that for all $x,\epsilon\in\R~x^4+\epsilon^4\geq 2x^2\epsilon^2$ we get
    \begin{align*}
        f(x,y)\geq (2\epsilon^2-4)x^2 + (2\epsilon^2-4)y^2 -2\epsilon^4
    \end{align*}
    the above inequality holds for all $\epsilon\in\R$ in particular for $\epsilon=\sqrt{3}$ that is
    \begin{align}
        f(x,y) &\geq 2(x^2+y^2) - 18\nonumber\\
                &= 2\|(x,y)\|^2 - 18    \label{lowerbound f}    
    \end{align}
    hence, take $\alpha=2$ and $\beta=-18$
    
    \item  Since $\displaystyle\lim_{\|(x,y)\|\to\infty}(2\|(x,y)\|^2 - 18)=\infty$ it follows from $\eqref{lowerbound f}$ $\displaystyle\lim_{\|(x,y)\|\to\infty}f(x,y)=\infty,$ thus, $f$ is coercive on $\R^2$ which closed. Therefore, by Theorem 3.8 of Chapter 1 of the lecture note, problem $\ref{pb}$ has a solution on $\R^2.$
\end{enumerate}
\end{solution}
\fi









































\end{document}